"""
Aggregator - æ”¶é›†å¹¶éªŒè¯æ‰€æœ‰ç« èŠ‚ç»“æœ
"""
from loguru import logger
from typing import Dict, Any
from app.agents.core.publisher.writing.state import DocumentState
from app.agents.core.publisher.writing import config

def chapter_aggregator(state: DocumentState) -> Dict[str, Any]:
    """
    èšåˆèŠ‚ç‚¹
    
    èŒè´£ï¼š
    1. ç­‰å¾…æ‰€æœ‰ Subgraph å®Œæˆï¼ˆLangGraph è‡ªåŠ¨å¤„ç†ï¼‰
    2. éªŒè¯å®Œæ•´æ€§
    3. è´¨é‡ç»Ÿè®¡
    4. å¼‚å¸¸æ£€æµ‹
    
    Args:
        state: DocumentState
        
    Returns:
        æ›´æ–°åçš„ state å­—æ®µ
    """
    logger.info("\nğŸ“Š [Aggregator] æ”¶é›†ç« èŠ‚ç»“æœ...")

    # è°ƒè¯•æ—¥å¿—
    logger.debug(f"  ğŸ” [DEBUG] State ç±»å‹: {type(state)}")
    logger.debug(f"  ğŸ” [DEBUG] State é”®: {list(state.keys())}")
    logger.debug(f"  ğŸ” [DEBUG] completed_chapters é”®å­˜åœ¨: {'completed_chapters' in state}")

    completed = state["completed_chapters"]

    logger.debug(f"  ğŸ” [DEBUG] completed_chapters ç±»å‹: {type(completed)}")
    logger.debug(f"  ğŸ” [DEBUG] completed_chapters å€¼: {completed}")
    logger.debug(f"  ğŸ” [DEBUG] completed_chapters é•¿åº¦: {len(completed)}")

    expected_count = len(state["main_document_outline"].sections)
    
    # === 1. å®Œæ•´æ€§æ£€æŸ¥ ===
    if len(completed) != expected_count:
        missing_ids = set(range(1, expected_count + 1)) - set(completed.keys())
        
        error_msg = (
            f"ç« èŠ‚ç¼ºå¤±ï¼æœŸæœ› {expected_count} ç« ï¼Œå®é™…å®Œæˆ {len(completed)} ç« ã€‚"
            f"ç¼ºå¤±ç« èŠ‚ID: {missing_ids}"
        )
        logger.error(f"  âŒ {error_msg}")
        raise ValueError(error_msg)

    logger.info(f"  âœ“ å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡ï¼š{len(completed)}/{expected_count} ç« èŠ‚")
    
    # === 2. æŒ‰é¡ºåºæ’åº ===
    sorted_chapters = dict(sorted(completed.items()))
    
    # === 3. è´¨é‡ç»Ÿè®¡ ===
    total_words = sum(ch["actual_word_count"] for ch in sorted_chapters.values())
    avg_score = sum(ch["quality_score"] for ch in sorted_chapters.values()) / expected_count
    
    revision_stats = {
        ch_id: ch["revision_count"]
        for ch_id, ch in sorted_chapters.items()
    }
    
    low_quality_chapters = [
        ch_id for ch_id, ch in sorted_chapters.items()
        if ch["quality_score"] < config.MIN_QUALITY_SCORE
    ]
    
    quality_stats = {
        "total_words": total_words,
        "avg_score": round(avg_score, 2),
        "revision_stats": revision_stats,
        "low_quality_chapters": low_quality_chapters,
    }
    
    logger.info(f"  âœ“ æ€»å­—æ•°: {total_words}")
    logger.info(f"  âœ“ å¹³å‡è´¨é‡åˆ†: {avg_score:.1f}")
    logger.info(f"  âœ“ ä¿®è®¢ç»Ÿè®¡: {revision_stats}")

    # === 4. å¼‚å¸¸æ£€æµ‹å’Œæ—¥å¿—è®°å½• ===
    warnings_count = 0

    # æ£€æŸ¥1ï¼šæ˜¯å¦æœ‰ä½è´¨é‡ç« èŠ‚
    if low_quality_chapters:
        logger.warning(f"  âš ï¸  å‘ç°ä½è´¨é‡ç« èŠ‚: {low_quality_chapters} (ä½äº {config.MIN_QUALITY_SCORE} åˆ†)")
        warnings_count += 1

    # æ£€æŸ¥2ï¼šå­—æ•°åˆ†å¸ƒæ˜¯å¦åˆç†
    word_counts = [ch["actual_word_count"] for ch in sorted_chapters.values()]
    if max(word_counts) > 2 * min(word_counts):
        logger.warning(f"  âš ï¸  ç« èŠ‚é•¿åº¦ä¸å¹³è¡¡: æœ€é•¿ {max(word_counts)} å­—, æœ€çŸ­ {min(word_counts)} å­—")
        warnings_count += 1

    if warnings_count == 0:
        logger.info(f"  âœ“ æœªå‘ç°å¼‚å¸¸\n")
    else:
        logger.warning(f"  âš ï¸  å‘ç° {warnings_count} ä¸ªè­¦å‘Š\n")
    
    # === è¿”å›æ›´æ–° ===
    # aggregator è´Ÿè´£ç»Ÿè®¡å’ŒéªŒè¯
    # - completed_chapters å·²é€šè¿‡ reducer è‡ªåŠ¨åˆå¹¶,ä¸åº”é‡å¤è¿”å›
    # - è­¦å‘Šä¿¡æ¯é€šè¿‡æ—¥å¿—è®°å½•ï¼Œä¸éœ€è¦å­˜å‚¨åœ¨ state ä¸­
    return {
        "quality_stats": quality_stats,
    }
