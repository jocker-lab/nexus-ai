# -*- coding: utf-8 -*-
"""
Document Reviewer - æ™ºèƒ½æ–‡æ¡£å®¡æŸ¥èŠ‚ç‚¹ï¼ˆç®€åŒ–ç‰ˆï¼‰

èŒè´£ï¼š
1. ä½¿ç”¨ LLM å¯¹æ•´åˆåçš„æ–‡æ¡£è¿›è¡Œå…¨å±€å®¡æŸ¥
2. è¯„ä¼°è¿è´¯æ€§ã€å®Œæ•´æ€§ã€è´¨é‡
3. å¯é€‰ï¼šè‡ªåŠ¨ä¿®å¤è½»å¾®é—®é¢˜
"""
from typing import Dict, Any
from loguru import logger
from langchain_deepseek import ChatDeepSeek
from app.agents.core.publisher.writing.state import DocumentState
from app.agents.schemas.review_schema import GlobalReviewResult
from app.agents.core.publisher.writing import config


async def document_reviewer(state: DocumentState) -> Dict[str, Any]:
    """
    æ™ºèƒ½æ–‡æ¡£å®¡æŸ¥èŠ‚ç‚¹ï¼ˆä½¿ç”¨ Structured Outputï¼‰

    è®¾è®¡ç†å¿µï¼š
    - ç®€åŒ–å®¡æŸ¥é€»è¾‘ï¼Œåªåšå¿…è¦çš„æ£€æŸ¥
    - ä½¿ç”¨ Structured Output ç¡®ä¿è¿”å›æ ¼å¼
    - è‡ªåŠ¨ä¿®å¤è½»å¾®é—®é¢˜ï¼ˆå¯é€‰ï¼‰
    """
    logger.info("\nğŸ” [Document Reviewer] æ™ºèƒ½å…¨å±€å®¡æŸ¥...")

    document = state["integrated_document"]
    total_word_count = state.get("document_metadata", {}).get("total_words", len(document))
    target_length = state["target_length"]
    avg_quality = state.get("quality_stats", {}).get("avg_score", 0)

    # === åˆå§‹åŒ– LLM ===
    llm = ChatDeepSeek(
        model=config.MODEL_NAME,
        max_tokens=config.MAX_TOKENS,
        temperature=config.TEMPERATURE,
    )

    # === 1. LLM å…¨å±€å®¡æŸ¥ï¼ˆä½¿ç”¨ Structured Outputï¼‰===
    logger.info("  â†³ æ‰§è¡Œ LLM æ™ºèƒ½å®¡æŸ¥...")

    try:
        llm_with_structure = llm.with_structured_output(GlobalReviewResult)

        # æ–‡æ¡£é¢„è§ˆï¼ˆé¿å… token è¿‡å¤šï¼‰
        doc_preview = document[:5000]
        if len(document) > 5000:
            doc_preview += f"\n\n... [ä¸­é—´çœç•¥ {len(document) - 5000} å­—ç¬¦] ...\n\n"
            doc_preview += document[-2000:]  # æ·»åŠ ç»“å°¾éƒ¨åˆ†

        # æ„å»ºå®¡æŸ¥ prompt
        system_prompt = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ–‡æ¡£å®¡æŸ¥ä¸“å®¶ã€‚

        ä»»åŠ¡ï¼šå¯¹æ•´ä»½æ–‡æ¡£è¿›è¡Œå…¨å±€è´¨é‡å®¡æŸ¥ã€‚
        
        å®¡æŸ¥ç»´åº¦ï¼š
        1. **è¿è´¯æ€§**ï¼šç« èŠ‚ä¹‹é—´æ˜¯å¦æµç•…è¿‡æ¸¡ã€é€»è¾‘æ˜¯å¦è¿è´¯
        2. **å®Œæ•´æ€§**ï¼šæ˜¯å¦ç¼ºå¤±é‡è¦å†…å®¹ã€ç»“æ„æ˜¯å¦å®Œæ•´
        3. **å†—ä½™æ€§**ï¼šæ˜¯å¦æœ‰é‡å¤å†…å®¹
        4. **æœ¯è¯­ä¸€è‡´æ€§**ï¼šä¸“ä¸šæœ¯è¯­ä½¿ç”¨æ˜¯å¦ç»Ÿä¸€
        5. **æ ¼å¼è§„èŒƒ**ï¼šMarkdown æ ¼å¼æ˜¯å¦æ­£ç¡®
        
        è¾“å‡ºè¦æ±‚ï¼š
        - ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºæ ¼å¼
        - overall_assessment: excellent/good/acceptable/needs_revision
        - coherence_score: 0-100 åˆ†
        - åˆ—å‡ºå‘ç°çš„ä¸»è¦é—®é¢˜ï¼ˆå¦‚æœæœ‰ï¼‰
        - ç»™å‡ºä¿®è®¢å»ºè®®ï¼ˆå¦‚æœéœ€è¦ï¼‰
        """

        user_prompt = f"""è¯·å®¡æŸ¥ä»¥ä¸‹æ–‡æ¡£ï¼š
        
        **æ–‡æ¡£ç»Ÿè®¡**ï¼š
        - æ€»å­—æ•°ï¼š{total_word_count} å­—ï¼ˆç›®æ ‡ï¼š{target_length} å­—ï¼‰
        - å¹³å‡ç« èŠ‚è´¨é‡ï¼š{avg_quality} åˆ†
        
        **æ–‡æ¡£å†…å®¹**ï¼š
        {doc_preview}
        
        ---
        è¯·è¿›è¡Œå…¨å±€å®¡æŸ¥å¹¶è¿”å›ç»“æ„åŒ–ç»“æœã€‚
        """

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        review_result = await llm_with_structure.ainvoke(messages)

        logger.info(f"    â†³ æ•´ä½“è¯„ä¼°: {review_result.overall_assessment}")
        logger.info(f"    â†³ è¿è´¯æ€§åˆ†æ•°: {review_result.coherence_score}")

        if review_result.redundancy_issues:
            logger.warning(f"    âš ï¸  å‘ç° {len(review_result.redundancy_issues)} ä¸ªå†—ä½™é—®é¢˜")

        if review_result.terminology_issues:
            logger.warning(f"    âš ï¸  å‘ç° {len(review_result.terminology_issues)} ä¸ªæœ¯è¯­é—®é¢˜")

    except Exception as e:
        logger.error(f"  âŒ å®¡æŸ¥å¤±è´¥: {e}", exc_info=True)

        # å›é€€ï¼šé»˜è®¤é€šè¿‡
        logger.info("  â†³ ä½¿ç”¨é»˜è®¤å®¡æŸ¥ç»“æœï¼ˆé€šè¿‡ï¼‰\n")

        review_result = GlobalReviewResult(
            overall_assessment="acceptable",
            coherence_score=75,
            redundancy_issues=[],
            terminology_issues=[],
            suggested_fixes=[],
            recommendation="approve"
        )

    # === 2. å†³ç­–åˆ†æ”¯ï¼ˆç®€åŒ–ï¼‰ ===
    recommendation = review_result.recommendation
    final_document = document

    if recommendation == "approve":
        logger.success("  âœ“ å®¡æŸ¥é€šè¿‡ï¼Œç›´æ¥è¾“å‡º\n")

    elif recommendation == "minor_fixes" and review_result.suggested_fixes:
        logger.info("  â†³ éœ€è¦è½»å¾®ä¿®å¤ï¼Œè‡ªåŠ¨åº”ç”¨...")

        try:
            # æ„å»ºä¿®å¤ prompt
            fixes_text = "\n".join([
                f"- {fix.location}: {fix.description} â†’ {fix.suggested_change}"
                for fix in review_result.suggested_fixes
            ])

            fix_prompt = f"""è¯·å¯¹ä»¥ä¸‹æ–‡æ¡£åº”ç”¨è¿™äº›ä¿®å¤ï¼š

            **ä¿®å¤æ¸…å•**ï¼š
            {fixes_text}
            
            **åŸæ–‡æ¡£**ï¼š
            {document}
            
            ---
            è¯·è¾“å‡ºä¿®å¤åçš„å®Œæ•´æ–‡æ¡£ï¼ˆMarkdown æ ¼å¼ï¼‰ã€‚
            """

            fix_response = await llm.ainvoke([{"role": "user", "content": fix_prompt}])
            final_document = fix_response.content.strip()

            logger.success(f"  âœ“ åº”ç”¨äº† {len(review_result.suggested_fixes)} ä¸ªä¿®å¤\n")

        except Exception as e:
            logger.warning(f"  âš ï¸  è‡ªåŠ¨ä¿®å¤å¤±è´¥: {e}")
            logger.info("  â†³ ä½¿ç”¨åŸæ–‡æ¡£\n")

    else:
        # major_revision æˆ–å…¶ä»–æƒ…å†µï¼Œä¹Ÿç›´æ¥é€šè¿‡ï¼ˆé¿å…è¿‡åº¦å®¡æŸ¥ï¼‰
        logger.info("  â†³ å»ºè®®è¿›è¡Œä¿®è®¢ï¼Œä½†è‡ªåŠ¨é€šè¿‡ï¼ˆé¿å…è¿‡åº¦å®¡æŸ¥ï¼‰\n")

    # === è¿”å›æ›´æ–° ===
    return {
        "global_review": review_result.model_dump(),
        "final_document": final_document,
    }
