# -*- coding: utf-8 -*-
"""
Document Integrator - æ™ºèƒ½æ–‡æ¡£æ•´åˆèŠ‚ç‚¹

èŒè´£ï¼š
1. å°†æ‰€æœ‰ç« èŠ‚å†…å®¹ä¼ é€’ç»™ LLM
2. è®© LLM è‡ªä¸»å®Œæˆæ–‡æ¡£æ•´åˆã€è¿‡æ¸¡ã€å‚è€ƒæ–‡çŒ®ç­‰
"""
from typing import Dict, Any
from loguru import logger
from app.agents.core.publisher.writing.state import DocumentState
from langchain.chat_models import init_chat_model
from app.agents.prompts.template import render_prompt_template


async def document_integrator(state: DocumentState) -> Dict[str, Any]:
    """
    æ™ºèƒ½æ–‡æ¡£æ•´åˆèŠ‚ç‚¹ï¼ˆå®Œå…¨ç”± LLM é©±åŠ¨ï¼‰

    Args:
        state: DocumentState

    Returns:
        {"document": str}
    """
    logger.info("\nğŸ“š [Document Integrator] æ™ºèƒ½æ–‡æ¡£æ•´åˆ...")

    chapters = state["completed_chapters"]
    outline = state["document_outline"]

    # === 1. å‡†å¤‡ç« èŠ‚å†…å®¹ï¼ˆæŒ‰é¡ºåºï¼‰ ===
    logger.info("  â†³ å‡†å¤‡ç« èŠ‚å†…å®¹...")

    sorted_chapters = sorted(chapters.items(), key=lambda x: x[0])
    total_chapters = len(sorted_chapters)

    chapters_content = []
    for ch_id, ch_data in sorted_chapters:
        chapter_text = f"""
        ---
        ç« èŠ‚ {ch_id}/{total_chapters}
        ---
        {ch_data['content']}
        """
        chapters_content.append(chapter_text)

    combined_chapters = "\n\n".join(chapters_content)

    # === 2. æ„å»º LLM Prompt ===
    logger.info("  â†³ è°ƒç”¨ LLM è¿›è¡Œæ™ºèƒ½æ•´åˆ...")

    llm = init_chat_model(
        "deepseek:deepseek-reasoner",
        max_tokens=16384,
        timeout=120,  # æ¨ç†æ¨¡å‹è€—æ—¶è¾ƒé•¿ï¼ŒåŠ å¤§è¶…æ—¶
    )

    system_prompt = render_prompt_template(
        "publisher_prompts/document_writing/document_integrator_system",
        {
            "language": outline.language,
            "writing_style": outline.writing_style,
            "writing_tone": outline.writing_tone,
        }
    )

    user_prompt = render_prompt_template(
        "publisher_prompts/document_writing/document_integrator_task",
        {
            "outline": outline,
            "total_chapters": total_chapters,
            "combined_chapters": combined_chapters,
        }
    )

    try:
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        response = await llm.ainvoke(messages)
        integrated_document = response.content.strip()

        if not integrated_document or len(integrated_document) < 100:
            raise ValueError("LLM è¿”å›çš„æ–‡æ¡£å†…å®¹è¿‡çŸ­")

        metadata = state.get("document_metadata", {})
        logger.success(f"  âœ“ æ™ºèƒ½æ•´åˆå®Œæˆ")
        logger.info(f"    - ç« èŠ‚æ•°: {total_chapters}")
        logger.info(f"    - æ€»å­—æ•°: {metadata.get('total_words', len(integrated_document))}")
        logger.info(f"    - å¹³å‡è¯„åˆ†: {metadata.get('avg_score', 'N/A')}\n")

        return {"document": integrated_document}

    except Exception as e:
        logger.error(f"  âŒ LLMæ•´åˆå¤±è´¥: {e}")
        logger.info("  â†³ ä½¿ç”¨é™çº§æ–¹æ¡ˆï¼ˆç®€å•æ‹¼æ¥ï¼‰...\n")

        fallback_document = f"# {outline.title}\n\n{combined_chapters}"
        return {"document": fallback_document}
