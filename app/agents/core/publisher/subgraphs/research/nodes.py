# -*- coding: utf-8 -*-
"""
@File    :   nodes.py
@Time    :   2025/11/5 08:42
@Author  :   pygao
@Version :   1.0
@Contact :   pygao.1@outlook.com
@License :   (C)Copyright 2025, GienTech Technology Co.,Ltd. All rights reserved.
@Desc    :   æ–‡ä»¶æè¿°
"""
from langchain_core.messages import HumanMessage
from loguru import logger
from datetime import datetime

from langgraph.types import Send, Command
from langchain.agents import create_agent
from langchain.chat_models import init_chat_model


from app.agents.tools.search.tavily_search import searcher
from app.agents.core.publisher.subgraphs.research.state import ResearcherState, SingleResearchState
from app.agents.prompts.template import apply_prompt_template, render_prompt_template


def plan_research(state: ResearcherState) -> list:
    """
    å…¥å£èŠ‚ç‚¹ï¼šå°†ç ”ç©¶ä»»åŠ¡åˆ†å‘ä¸ºå¹¶è¡Œæ‰§è¡Œçš„å­ä»»åŠ¡

    å·¥ä½œæµç¨‹ï¼š
    1. è¯»å– research_topics åˆ—è¡¨
    2. ä¸ºæ¯ä¸ª topic åˆ›å»ºä¸€ä¸ª Send å¯¹è±¡
    3. è¿”å› Send åˆ—è¡¨ï¼ŒLangGraph è‡ªåŠ¨å¹¶è¡Œæ‰§è¡Œ

    Args:
        state: ResearcherState - åŒ…å«æ‰€æœ‰ç ”ç©¶ä¸»é¢˜

    Returns:
        List[Send] - å¹¶è¡Œä»»åŠ¡åˆ—è¡¨
    """
    topics = state["research_topics"]
    need_search = state["need_search"]
    language = state["language"]

    logger.info(f"ğŸ“š å¼€å§‹åˆ†å‘ {len(topics)} ä¸ªç ”ç©¶ä»»åŠ¡")

    # åˆ›å»ºå¹¶è¡Œä»»åŠ¡ï¼ˆLangGraph 1.0 åŸç”Ÿæ”¯æŒï¼‰
    sends = [
        Send(
            "execute_single_research",  # ç›®æ ‡èŠ‚ç‚¹åï¼ˆå¿…é¡»ä¸ add_node ä¸€è‡´ï¼‰
            {
                "current_research_topic": topic,
                "need_search": need_search,
                "language": language
            }
        )
        for topic in topics
    ]

    logger.info(f"âœ… åˆ†å‘å®Œæˆï¼Œå°†å¹¶è¡Œæ‰§è¡Œ {len(sends)} ä¸ªä»»åŠ¡")
    return Command(goto=sends)



async def execute_single_research_node(state: SingleResearchState):
    """
    æ‰§è¡ŒèŠ‚ç‚¹ï¼šå¤„ç†å•ä¸ªç ”ç©¶ä»»åŠ¡

    æ­¤èŠ‚ç‚¹ä¼šè¢«å¹¶è¡Œè°ƒç”¨å¤šæ¬¡ï¼ˆæ¯ä¸ªä¸»é¢˜ä¸€æ¬¡ï¼‰

    å·¥ä½œæµç¨‹ï¼š
    1. ä»çŠ¶æ€ä¸­è¯»å– current_research_topic
    2. æ ¹æ® need_search å†³å®šæ˜¯å¦ä½¿ç”¨æœç´¢å·¥å…·
    3. è°ƒç”¨ LLM ç”Ÿæˆç ”ç©¶ç»“æœ
    4. è¿”å›ç»“æœï¼ˆè‡ªåŠ¨èšåˆåˆ°ä¸»çŠ¶æ€çš„ results å­—æ®µï¼‰

    Args:
        state: SingleResearchState - å•ä»»åŠ¡çŠ¶æ€

    Returns:
        dict - åŒ…å« results å­—æ®µçš„å­—å…¸
    """

    # è¯»å–ä»»åŠ¡å‚æ•°
    topic = state["current_research_topic"]
    language = state["language"]

    logger.info(f"ğŸ” æ‰§è¡Œç ”ç©¶ä»»åŠ¡: {topic}")

    system_prompt = render_prompt_template("researcher_prompts/researcher", state)

    task_prompt = f"""
    Research the following topic and provide comprehensive information:

    Topic: {topic}

    Requirements:
    - Provide detailed and accurate information
    - Include key facts, concepts, and relevant context
    - Response language: {language}
    """
    # ä½¿ç”¨æ”¯æŒæµå¼çš„ LLM
    llm = init_chat_model("deepseek:deepseek-chat")

    try:

        # ä½¿ç”¨æœç´¢å·¥å…·
        logger.info(f"   ğŸŒ ä½¿ç”¨æœç´¢å·¥å…·æŸ¥è¯¢: {topic}")
        search_tools = [searcher]
        search_agent = create_agent(
            llm,
            search_tools,
            system_prompt=system_prompt,
        )

        # ä½¿ç”¨ ainvoke æ”¯æŒå¼‚æ­¥å’Œæµå¼
        agent_response = await search_agent.ainvoke(
            {"messages": [HumanMessage(content=task_prompt)]}
        )
        response_content = agent_response['messages'][-1].content
        logger.success(f"   âœ… æœç´¢å®Œæˆ: {topic} ({len(response_content)} å­—ç¬¦)")

        # è¿”å›ç»“æœåˆ° results åˆ—è¡¨ï¼ˆä¼šè¢« operator.add è‡ªåŠ¨èšåˆï¼‰
        return {
            "results": [{
                "topic": topic,
                "result": response_content,
                "success": True,
                "timestamp": datetime.now().isoformat()
            }]
        }


    except Exception as e:
        import traceback
        error_traceback = traceback.format_exc()
        error_type = type(e).__name__
        error_message = str(e)

        logger.error(f"   âŒ ç ”ç©¶å¤±è´¥: {topic}")
        logger.error(f"   é”™è¯¯ç±»å‹: {error_type}")
        logger.error(f"   é”™è¯¯ä¿¡æ¯: {error_message}")
        logger.error(f"   å®Œæ•´å †æ ˆ:\n{error_traceback}")
        logger.error(f"   âŒ ç ”ç©¶å¤±è´¥: {topic} - {e}")
        return {
            "results": [{
                "topic": topic,
                "result": f"Error: {str(e)}",
                "success": False,
                "timestamp": datetime.now().isoformat()
            }]
        }


def aggregate_results(state: ResearcherState):
    """
    èšåˆèŠ‚ç‚¹ï¼šæ•´ç†æ‰€æœ‰ç ”ç©¶ç»“æœå¹¶æ ¼å¼åŒ–è¾“å‡º

    å·¥ä½œæµç¨‹ï¼š
    1. ä» state.results ä¸­è¯»å–æ‰€æœ‰ä»»åŠ¡ç»“æœ
    2. ç»Ÿè®¡æˆåŠŸ/å¤±è´¥æ•°é‡
    3. æ ¼å¼åŒ–ä¸ºæ˜“è¯»çš„å­—ç¬¦ä¸²

    Args:
        state: ResearcherState - åŒ…å«æ‰€æœ‰èšåˆåçš„ç»“æœ

    Returns:
        dict - åŒ…å« final_result, success_count, total_count
    """
    results = state.get("results", [])
    total = len(results)
    success = sum(1 for r in results if r.get("success", False))

    logger.success(f"ğŸ‰ ç ”ç©¶ä»»åŠ¡å…¨éƒ¨å®Œæˆï¼æˆåŠŸ: {success}/{total}")


    # æ ¼å¼åŒ–æœ€ç»ˆç»“æœ
    formatted_parts = []
    for i, result_data in enumerate(results, 1):
        topic = result_data.get("topic", "Unknown")
        result = result_data.get("result", "")
        status = "âœ…" if result_data.get("success") else "âŒ"

        formatted_parts.append(
            f"{status} ä»»åŠ¡ {i}: {topic}\n"
            f"{'=' * 60}\n"
            f"{result}\n"
        )

    final_result = "\n\n".join(formatted_parts)

    logger.info(f"ğŸ“Š æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆå®Œæˆï¼Œæ€»è®¡ {len(final_result)} å­—ç¬¦")

    return {
        "research_draft": final_result,
    }