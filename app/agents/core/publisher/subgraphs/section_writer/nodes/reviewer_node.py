# -*- coding: utf-8 -*-
"""
@File    :   reviewer_node.py
@Time    :   2025/11/14 10:14
@Author  :   pygao
@Version :   1.0
@Contact :   pygao.1@outlook.com
@License :   (C)Copyright 2025, GienTech Technology Co.,Ltd. All rights reserved.
@Desc    :   æ–‡ä»¶æè¿°
"""
from typing import Dict, Any
from loguru import logger
from app.agents.core.publisher.subgraphs.section_writer.state import ChapterState
from app.agents.schemas.review_schema import ReviewResult
from langchain.chat_models import init_chat_model
from langchain.messages import HumanMessage, SystemMessage
from app.agents.prompts.template import render_prompt_template


async def review_draft(state: ChapterState) -> Dict[str, Any]:
    """
    ã€ç« èŠ‚å®¡æŸ¥èŠ‚ç‚¹ã€‘- ä½¿ç”¨ Structured Output çš„å®¡æŸ¥è€…

    èŒè´£ï¼š
    1. è°ƒç”¨ LLM å¯¹å½“å‰è‰ç¨¿è¿›è¡Œå¤šç»´åº¦ç»“æ„åŒ–è¯„å®¡
    2. è·å–æ ‡å‡†åŒ–çš„ ReviewResultï¼ˆåŒ…å«è¯„åˆ†ã€é—®é¢˜åˆ—è¡¨ã€ä¿®æ”¹å»ºè®®ç­‰ï¼‰
    3. è®°å½•æœ¬æ¬¡å®¡æŸ¥ç»“æœåˆ°å†å²ï¼Œå¹¶æ›´æ–° revision_count

    æ³¨æ„ï¼šæœ¬èŠ‚ç‚¹åªè´Ÿè´£â€œè¯„å®¡â€ï¼Œä¸è´Ÿè´£â€œå†³ç­–æ˜¯å¦ä¿®è®¢â€ã€‚
          å†³ç­–é€»è¾‘ç»Ÿä¸€æ”¾åœ¨å¤–å±‚çš„è·¯ç”±å‡½æ•°ï¼ˆdecide_after_reviewï¼‰ä¸­ï¼Œæ›´ç¬¦åˆ LangGraph çš„çŠ¶æ€æœºè®¾è®¡ç†å¿µã€‚
    """


    chapter_id = state["chapter_id"]
    chapter_title = state["chapter_outline"].title
    

    logger.info(f"ğŸ“Š [Chapter {chapter_id}] ã€Š{chapter_title}ã€‹ Reviewer: å¼€å§‹å®¡æŸ¥...")

    # åˆå§‹åŒ– LLMï¼ˆè¿™é‡Œå»ºè®®åç»­æ”¹ä¸ºä» config ä¸­è¯»å–ï¼Œä¾¿äºåˆ‡æ¢æ¨¡å‹ï¼‰
    llm = init_chat_model("deepseek:deepseek-chat")

    system_message = render_prompt_template(
        "publisher_prompts/chapter_writing/chapter_review_system",
        {
            "language": state["document_outline"].language,
        },
    )

    user_message = render_prompt_template(
        "publisher_prompts/chapter_writing/chapter_review_task",
        state
    )
    try:

        messages = [
            SystemMessage(content=system_message),
            HumanMessage(content=user_message)
        ]

        # ç»‘å®šç»“æ„åŒ–è¾“å‡ºï¼ˆå…³é”®ï¼ç¡®ä¿è¿”å›çš„æ˜¯ Pydantic å¯¹è±¡ï¼‰
        structured_llm = llm.with_structured_output(ReviewResult)

        # æ„é€  Promptï¼ˆä½¿ç”¨ä½ å·²æœ‰çš„æ¨¡æ¿ç³»ç»Ÿï¼‰


        # å¼‚æ­¥è°ƒç”¨ï¼Œè·å–ç»“æ„åŒ–ç»“æœ
        review_result: ReviewResult = await structured_llm.ainvoke(messages)

        logger.success(
            f"âœ… å®¡æŸ¥å®Œæˆ | æ€»åˆ†: {review_result.score}/100 | "
            f"å†³ç­–: {review_result.status.upper()} | "
            f"å®¡æŸ¥é—®é¢˜è¯´æ˜: {review_result.general_feedback} | "
            f"é—®é¢˜æ•°: {len(review_result.actionable_suggestions)}"
        )

    except Exception as exc:
        logger.error(f"âŒ [Chapter {chapter_id}] ç« èŠ‚å®¡æŸ¥å¤±è´¥: {exc}", exc_info=True)

        # å¤±è´¥æ—¶è¿”å›ä¸€ä¸ªä¿å®ˆçš„ã€èƒ½è®©æµç¨‹ç»§ç»­çš„å®‰å…¨é»˜è®¤ç»“æœ
        review_result = ReviewResult(
            status="revise",
            score=40,
            general_feedback="ã€è‡ªåŠ¨å®¡æŸ¥å¤±è´¥ã€‘ç”±äº LLM è°ƒç”¨å¼‚å¸¸ï¼Œç³»ç»Ÿæ— æ³•å®Œæˆæ­£å¸¸è¯„å®¡ï¼Œå·²æ ‡è®°ä¸ºéœ€è¦ä¿®è®¢ã€‚",
            actionable_suggestions=[
                "è¯·æ£€æŸ¥ç« èŠ‚è‰ç¨¿æ˜¯å¦åŒ…å«å¼‚å¸¸æ ¼å¼ï¼ˆå¦‚è¶…é•¿ä»£ç å—ã€ç‰¹æ®Šå­—ç¬¦ç­‰ï¼‰",
                "å»ºè®®é‡æ–°ç”Ÿæˆè¯¥ç« èŠ‚è‰ç¨¿åå†æ¬¡æäº¤å®¡æŸ¥"
            ],
        )

    # === æ›´æ–°çŠ¶æ€ ===
    current_revision_count = state.get("revision_count", 0) + 1

    logger.info(f"â†³ ä¿®è®¢æ¬¡æ•°: {current_revision_count} ")

    return {
        "latest_review": review_result,  # å½“å‰æœ€æ–°çš„å®¡æŸ¥ç»“æœï¼ˆä¾›è·¯ç”±èŠ‚ç‚¹å†³ç­–ä½¿ç”¨ï¼‰
        "revision_count": current_revision_count,  # å…³é”®è®¡æ•°å™¨ï¼Œå†³å®šæ˜¯å¦è¿›å…¥â€œå¼ºåˆ¶é€šè¿‡â€æˆ–â€œäººå·¥ä»‹å…¥â€
    }
