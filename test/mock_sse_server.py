# -*- coding: utf-8 -*-
"""
@File    :   mock_sse_server.py
@Time    :   2025/12/02
@Author  :   Claude
@Desc    :   Mock SSE æµ‹è¯•æœåŠ¡å™¨ - ä½¿ç”¨å½•åˆ¶çš„ JSONL æ•°æ®æ¨¡æ‹ŸçœŸå® SSE æµ
             ç”¨äºå‰ç«¯å¼€å‘æµ‹è¯•ï¼ŒèŠ‚çœ LLM tokens
"""

import asyncio
import json
import os
from datetime import datetime
from pathlib import Path
from typing import Optional, List, Dict, Any
from contextlib import asynccontextmanager

from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, FileResponse
from pydantic import BaseModel
from loguru import logger

# ==================== é…ç½® ====================

# JSONL æ•°æ®ç›®å½•
JSONL_DIR = Path(__file__).parent.parent / "logs" / "sse_streams_logs"

# æµå¼å»¶è¿Ÿé…ç½®ï¼ˆç§’ï¼‰
DEFAULT_CHUNK_DELAY = 0.02  # é»˜è®¤ chunk é—´éš”
DEFAULT_NODE_DELAY = 0.1    # node_start ç­‰äº‹ä»¶é—´éš”

# å¯ç”¨çš„æµ‹è¯•åœºæ™¯
SCENARIOS = {
    "start_to_interrupt": "sse_chat_001_20251202_110016.jsonl",  # æ–°å¯¹è¯åˆ°ä¸­æ–­
    "resume_to_complete": "sse_chat_001_20251202_110551.jsonl",  # ä»ä¸­æ–­æ¢å¤åˆ°å®Œæˆ
}


# ==================== æ•°æ®æ¨¡å‹ ====================

class MockChatRequest(BaseModel):
    """æ¨¡æ‹ŸèŠå¤©è¯·æ±‚ - ç®€åŒ–ç‰ˆ"""
    user_id: str = "user_001"
    chat_id: str = "mock_chat_001"
    message: str = ""
    agent_name: str = "publisher"  # ä»£ç†åç§°ï¼Œé¢„ç•™å­—æ®µï¼Œå½“å‰æœªä½¿ç”¨


# ==================== JSONL æ•°æ®åŠ è½½å™¨ ====================

class JsonlDataLoader:
    """JSONL æ•°æ®åŠ è½½å’Œç®¡ç†"""

    def __init__(self, jsonl_dir: Path):
        self.jsonl_dir = jsonl_dir
        self._cache: Dict[str, List[Dict]] = {}

    def list_available_files(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ JSONL æ–‡ä»¶"""
        if not self.jsonl_dir.exists():
            return []
        return [f.name for f in self.jsonl_dir.glob("*.jsonl")]

    def load_file(self, filename: str) -> List[Dict[str, Any]]:
        """åŠ è½½å•ä¸ª JSONL æ–‡ä»¶"""
        if filename in self._cache:
            return self._cache[filename]

        filepath = self.jsonl_dir / filename
        if not filepath.exists():
            raise FileNotFoundError(f"JSONL file not found: {filepath}")

        events = []
        with open(filepath, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                try:
                    events.append(json.loads(line))
                except json.JSONDecodeError as e:
                    logger.warning(f"Skip invalid JSON at line {line_num}: {e}")

        self._cache[filename] = events
        logger.info(f"ğŸ“‚ Loaded {len(events)} events from {filename}")
        return events

    def get_scenario_events(self, scenario: str) -> List[Dict[str, Any]]:
        """æ ¹æ®åœºæ™¯åè·å–äº‹ä»¶åˆ—è¡¨"""
        if scenario not in SCENARIOS:
            available = list(SCENARIOS.keys())
            raise ValueError(f"Unknown scenario: {scenario}. Available: {available}")

        filename = SCENARIOS[scenario]
        return self.load_file(filename)


# ==================== SSE æµæ¨¡æ‹Ÿå™¨ ====================

class SSEStreamSimulator:
    """SSE æµæ¨¡æ‹Ÿå™¨ - å¸¦çœŸå®å»¶è¿Ÿå’ŒçŠ¶æ€å›è°ƒ"""

    def __init__(self, events: List[Dict], speed_factor: float = 1.0,
                 on_interrupt: callable = None, on_complete: callable = None):
        self.events = events
        self.speed_factor = speed_factor
        self._prev_timestamp: Optional[datetime] = None
        self.on_interrupt = on_interrupt  # interrupt äº‹ä»¶å›è°ƒ
        self.on_complete = on_complete    # complete äº‹ä»¶å›è°ƒ

    def _parse_timestamp(self, ts_str: str) -> datetime:
        """è§£ææ—¶é—´æˆ³"""
        return datetime.fromisoformat(ts_str)

    def _calculate_delay(self, event: Dict) -> float:
        """è®¡ç®—äº‹ä»¶é—´çš„å»¶è¿Ÿæ—¶é—´"""
        event_type = event.get("type", "")

        # åŸºäºäº‹ä»¶ç±»å‹çš„é»˜è®¤å»¶è¿Ÿ
        if event_type == "chunk":
            base_delay = DEFAULT_CHUNK_DELAY
        elif event_type in ("node_start", "node_update", "usage"):
            base_delay = DEFAULT_NODE_DELAY
        elif event_type in ("start", "resume", "complete", "interrupt"):
            base_delay = 0.05
        else:
            base_delay = DEFAULT_CHUNK_DELAY

        # å¦‚æœæœ‰æ—¶é—´æˆ³ï¼Œä½¿ç”¨çœŸå®çš„æ—¶é—´é—´éš”
        if "timestamp" in event and self._prev_timestamp:
            try:
                current_ts = self._parse_timestamp(event["timestamp"])
                real_delay = (current_ts - self._prev_timestamp).total_seconds()
                # ä½¿ç”¨çœŸå®å»¶è¿Ÿï¼Œä½†é™åˆ¶æœ€å¤§å€¼
                base_delay = min(max(real_delay, 0.001), 1.0)
            except (ValueError, TypeError):
                pass

        return base_delay * self.speed_factor

    async def stream(self):
        """ç”Ÿæˆ SSE æµ"""
        logger.info(f"ğŸš€ Starting SSE stream simulation with {len(self.events)} events")

        for i, event in enumerate(self.events):
            # è®¡ç®—å»¶è¿Ÿ
            delay = self._calculate_delay(event)
            event_type = event.get("type", "message")

            # æ›´æ–°ä¸Šä¸€ä¸ªæ—¶é—´æˆ³
            if "timestamp" in event:
                try:
                    self._prev_timestamp = self._parse_timestamp(event["timestamp"])
                except (ValueError, TypeError):
                    pass

            # æ ¼å¼åŒ–ä¸º SSE æ ¼å¼ - å…¼å®¹ frontend_v4_mock.html
            # å‰ç«¯æœŸæœ›æ ¼å¼: data: {"type": "...", "data": {...}}\n\n
            sse_event = {
                "type": event_type,
                "data": event.get("data", {})
            }
            sse_message = f"data: {json.dumps(sse_event, ensure_ascii=False)}\n\n"

            # æ—¥å¿—ï¼ˆä»…è®°å½•å…³é”®äº‹ä»¶ï¼‰
            if event_type in ("start", "resume", "node_start", "interrupt", "complete", "usage"):
                logger.debug(f"ğŸ“¤ [{i+1}/{len(self.events)}] {event_type}")

            yield sse_message

            # ğŸ”¥ è§¦å‘çŠ¶æ€å›è°ƒ
            if event_type == "interrupt" and self.on_interrupt:
                self.on_interrupt()
            elif event_type == "complete" and self.on_complete:
                self.on_complete()

            # å»¶è¿Ÿ
            if delay > 0:
                await asyncio.sleep(delay)

        logger.info("âœ… SSE stream simulation completed")


# ==================== FastAPI åº”ç”¨ ====================

# å…¨å±€æ•°æ®åŠ è½½å™¨
data_loader = JsonlDataLoader(JSONL_DIR)


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    logger.info("=" * 60)
    logger.info("ğŸ­ Mock SSE Server Starting...")
    logger.info(f"ğŸ“‚ JSONL Directory: {JSONL_DIR}")
    logger.info(f"ğŸ“‹ Available scenarios: {list(SCENARIOS.keys())}")

    # é¢„åŠ è½½æ•°æ®
    for scenario, filename in SCENARIOS.items():
        try:
            events = data_loader.load_file(filename)
            logger.info(f"  - {scenario}: {len(events)} events")
        except FileNotFoundError:
            logger.warning(f"  - {scenario}: FILE NOT FOUND ({filename})")

    logger.info("=" * 60)
    yield
    logger.info("ğŸ›‘ Mock SSE Server Stopped")


app = FastAPI(
    title="Mock SSE Server",
    description="ç”¨äºå‰ç«¯æµ‹è¯•çš„ Mock SSE æœåŠ¡å™¨ï¼Œä½¿ç”¨å½•åˆ¶çš„ JSONL æ•°æ®",
    version="1.0.0",
    lifespan=lifespan
)

# CORS é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ==================== API ç«¯ç‚¹ ====================

@app.get("/")
async def root():
    """æœåŠ¡å™¨ä¿¡æ¯"""
    return {
        "name": "Mock SSE Server",
        "version": "1.0.0",
        "description": "ç”¨äºå‰ç«¯æµ‹è¯•çš„ Mock SSE æœåŠ¡å™¨",
        "endpoints": {
            "/api/v1/chat/stream": "POST - æ¨¡æ‹Ÿ SSE æµ",
            "/api/v1/scenarios": "GET - åˆ—å‡ºå¯ç”¨åœºæ™¯",
            "/api/v1/files": "GET - åˆ—å‡º JSONL æ–‡ä»¶",
            "/health": "GET - å¥åº·æ£€æŸ¥",
        }
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}


@app.get("/api/v1/scenarios")
async def list_scenarios():
    """åˆ—å‡ºå¯ç”¨çš„æµ‹è¯•åœºæ™¯"""
    result = {}
    for scenario, filename in SCENARIOS.items():
        try:
            events = data_loader.load_file(filename)
            # è·å–åœºæ™¯æ‘˜è¦
            first_event = events[0] if events else {}
            last_event = events[-1] if events else {}
            result[scenario] = {
                "filename": filename,
                "event_count": len(events),
                "starts_with": first_event.get("type"),
                "ends_with": last_event.get("type"),
                "description": _get_scenario_description(scenario)
            }
        except FileNotFoundError:
            result[scenario] = {"error": "file not found", "filename": filename}

    return {"scenarios": result}


@app.get("/api/v1/files")
async def list_files():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ JSONL æ–‡ä»¶"""
    files = data_loader.list_available_files()
    return {
        "directory": str(JSONL_DIR),
        "files": files,
        "count": len(files)
    }


# ğŸ”¥ å…¨å±€çŠ¶æ€ï¼šè®°å½•æ¯ä¸ª chat_id æ˜¯å¦å¤„äºä¸­æ–­çŠ¶æ€
chat_interrupt_states: Dict[str, bool] = {}


@app.post("/api/v1/chat/stream")
async def mock_chat_stream(request: MockChatRequest):
    """
    æ¨¡æ‹Ÿ SSE èŠå¤©æµ - è‡ªåŠ¨åˆ¤æ–­åœºæ™¯

    åœºæ™¯è‡ªåŠ¨åˆ¤æ–­é€»è¾‘:
    - å¦‚æœ chat_id å¤„äºä¸­æ–­çŠ¶æ€ â†’ resume_to_complete
    - å¦åˆ™ â†’ start_to_interrupt

    æ’­æ”¾å®Œ interrupt äº‹ä»¶åè‡ªåŠ¨æ ‡è®°ä¸ºä¸­æ–­çŠ¶æ€
    æ’­æ”¾å®Œ complete äº‹ä»¶åè‡ªåŠ¨æ¸…é™¤ä¸­æ–­çŠ¶æ€
    """
    chat_id = request.chat_id

    # ğŸ”¥ è‡ªåŠ¨åˆ¤æ–­åœºæ™¯
    is_interrupted = chat_interrupt_states.get(chat_id, False)
    scenario = "resume_to_complete" if is_interrupted else "start_to_interrupt"

    logger.info("=" * 50)
    logger.info(f"ğŸ“¨ Mock Stream Request")
    logger.info(f"   User ID: {request.user_id}")
    logger.info(f"   Chat ID: {chat_id}")
    logger.info(f"   Message: {request.message[:50]}..." if request.message else "   Message: (empty)")
    logger.info(f"   Is Interrupted: {is_interrupted}")
    logger.info(f"   Auto Scenario: {scenario}")
    logger.info("=" * 50)

    try:
        events = data_loader.get_scenario_events(scenario)
    except (FileNotFoundError, ValueError) as e:
        return {"error": str(e)}

    # ğŸ”¥ çŠ¶æ€å›è°ƒå‡½æ•°
    def on_interrupt():
        chat_interrupt_states[chat_id] = True
        logger.info(f"ğŸ”” Chat {chat_id} marked as INTERRUPTED")

    def on_complete():
        chat_interrupt_states[chat_id] = False
        logger.info(f"âœ… Chat {chat_id} marked as COMPLETED")

    # åˆ›å»ºæµæ¨¡æ‹Ÿå™¨ï¼ˆå¸¦çŠ¶æ€å›è°ƒï¼‰
    # ä½¿ç”¨å›ºå®š speed_factor=0.5ï¼ˆåŠ é€Ÿ 2 å€ï¼‰
    simulator = SSEStreamSimulator(
        events,
        speed_factor=0.5,
        on_interrupt=on_interrupt,
        on_complete=on_complete
    )

    return StreamingResponse(
        simulator.stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
            "Access-Control-Allow-Origin": "*",
        }
    )


@app.post("/api/chat/completions")
async def mock_chat_completions(request: Request):
    """
    å…¼å®¹åŸ API è·¯å¾„ - /api/chat/completions
    è‡ªåŠ¨åˆ¤æ–­åœºæ™¯ï¼ˆåŸºäº chat_id çŠ¶æ€ï¼‰
    """
    body = await request.json()
    chat_id = body.get("chat_id", "mock_chat")

    # ğŸ”¥ è‡ªåŠ¨åˆ¤æ–­åœºæ™¯
    is_interrupted = chat_interrupt_states.get(chat_id, False)
    scenario = "resume_to_complete" if is_interrupted else "start_to_interrupt"

    logger.info("=" * 50)
    logger.info(f"ğŸ“¨ Mock /api/chat/completions Request")
    logger.info(f"   Chat ID: {chat_id}")
    logger.info(f"   Is Interrupted: {is_interrupted}")
    logger.info(f"   Auto Scenario: {scenario}")
    logger.info("=" * 50)

    try:
        events = data_loader.get_scenario_events(scenario)
    except (FileNotFoundError, ValueError) as e:
        return {"error": str(e)}

    # ğŸ”¥ çŠ¶æ€å›è°ƒ
    def on_interrupt():
        chat_interrupt_states[chat_id] = True
        logger.info(f"ğŸ”” Chat {chat_id} marked as INTERRUPTED")

    def on_complete():
        chat_interrupt_states[chat_id] = False
        logger.info(f"âœ… Chat {chat_id} marked as COMPLETED")

    simulator = SSEStreamSimulator(
        events,
        speed_factor=0.3,
        on_interrupt=on_interrupt,
        on_complete=on_complete
    )

    return StreamingResponse(
        simulator.stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
            "Access-Control-Allow-Origin": "*",
        }
    )


# ==================== è¾…åŠ©å‡½æ•° ====================

def _get_scenario_description(scenario: str) -> str:
    """è·å–åœºæ™¯æè¿°"""
    descriptions = {
        "start_to_interrupt": "æ–°å¯¹è¯å¼€å§‹ï¼Œæ‰§è¡Œåˆ° HUMAN_INVOLVEMENT æ­¥éª¤æ—¶ä¸­æ–­ï¼Œç­‰å¾…ç”¨æˆ·è¾“å…¥",
        "resume_to_complete": "ä»ä¸­æ–­çŠ¶æ€æ¢å¤ï¼Œç»§ç»­æ‰§è¡Œç›´åˆ°å®Œæˆ WRITING_BLUEPRINT æ­¥éª¤",
    }
    return descriptions.get(scenario, "No description")


# ==================== å…¥å£ ====================

if __name__ == "__main__":
    import uvicorn

    # é…ç½®æ—¥å¿—
    logger.remove()
    logger.add(
        lambda msg: print(msg, end=""),
        format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | {message}",
        level="DEBUG",
        colorize=True
    )

    print("\n" + "=" * 60)
    print("ğŸ­ Mock SSE Server for Frontend Testing")
    print("=" * 60)
    print(f"ğŸ“‚ Data source: {JSONL_DIR}")
    print(f"ğŸŒ Server URL: http://localhost:8001")
    print(f"ğŸ“‹ API Docs: http://localhost:8001/docs")
    print("=" * 60 + "\n")

    uvicorn.run(
        "mock_sse_server:app",
        host="0.0.0.0",
        port=8001,
        reload=True,
        log_level="info"
    )
