# -*- coding: utf-8 -*-
"""
@File    :   test_document_writing_graph.py
@Time    :   2025/11/18 10:15
@Author  :   pygao
@Version :   1.0
@Contact :   pygao.1@outlook.com
@License :   (C)Copyright 2025, GienTech Technology Co.,Ltd. All rights reserved.
@Desc    :   Document Writing Graph å®Œæ•´æµ‹è¯•
"""

import asyncio
from loguru import logger

from app.agents.schemas.document_outline_schema import DocumentOutline, Section, SubSection
from app.agents.core.publisher.writing.agent import create_main_graph
from app.agents.core.publisher.writing.state import DocumentState
from dotenv import load_dotenv

load_dotenv()


# ========== æµ‹è¯•æ•°æ® ==========

document_outline = DocumentOutline(
    title="äººå·¥æ™ºèƒ½æŠ€æœ¯å‘å±•æŠ¥å‘Š",
    language="zh",
    target_audience="æŠ€æœ¯ç®¡ç†è€…ã€AIç ”ç©¶äººå‘˜ã€æŠ•èµ„å†³ç­–è€…",
    writing_style="business",
    writing_tone="authoritative",
    writing_purpose="ä¸ºè¯»è€…æä¾›AIæŠ€æœ¯å‘å±•çš„å…¨é¢è§†è§’ï¼ŒåŒ…æ‹¬æŠ€æœ¯è¶‹åŠ¿ã€åº”ç”¨æ¡ˆä¾‹å’Œæœªæ¥å±•æœ›",
    key_themes=[
        "å¤§æ¨¡å‹æŠ€æœ¯æ¼”è¿›",
        "AIå•†ä¸šåº”ç”¨å®è·µ",
    ],
    estimated_total_words=3000,
    sections=[
        Section(
            title="ç¬¬ä¸€ç«  å¤§æ¨¡å‹æŠ€æœ¯ç°çŠ¶",
            description="åˆ†æå½“å‰å¤§è¯­è¨€æ¨¡å‹çš„æŠ€æœ¯å‘å±•ç°çŠ¶ã€æ ¸å¿ƒçªç ´å’Œä¸»æµæ¶æ„",
            writing_guidance="é‡‡ç”¨æŠ€æœ¯æ¼”è¿›çš„æ—¶é—´çº¿è§†è§’ï¼Œä»æ¶æ„åˆ›æ–°åˆ°æ¨¡å‹å¯¹æ¯”åˆ°è®­ç»ƒæŠ€æœ¯ï¼Œå±‚å±‚é€’è¿›ã€‚",
            content_requirements="éœ€è¦åŒ…å«ï¼š1) Transformeræ¶æ„æ¼”è¿›è„‰ç»œ 2) ä¸»æµæ¨¡å‹çš„å‚æ•°è§„æ¨¡å’Œæ€§èƒ½å¯¹æ¯”æ•°æ®",
            visual_elements=False,
            estimated_words=1500,
            writing_priority="high",
            subsections=[
                SubSection(
                    sub_section_title="Transformeræ¶æ„æ¼”è¿›",
                    description="è¿½æº¯Transformerä»è¯ç”Ÿåˆ°ç°åœ¨çš„æŠ€æœ¯æ¼”è¿›è·¯å¾„",
                    writing_guidance="""
                    ã€æ®µè½1 - èµ·æºä¸çªç ´ã€‘(150-200å­—)
                    - ä»2017å¹´åŸå§‹è®ºæ–‡åˆ‡å…¥ï¼Œè¯´æ˜Transformerçš„é©å‘½æ€§æ„ä¹‰
                    - ç®€è¿°å…¶æ›¿ä»£RNN/LSTMæˆä¸ºä¸»æµæ¶æ„çš„æ ¸å¿ƒåŸå› 
                    - ç‚¹æ˜è‡ªæ³¨æ„åŠ›æœºåˆ¶(Self-Attention)è§£å†³çš„å…³é”®é—®é¢˜

                    ã€æ®µè½2 - æ ¸å¿ƒæœºåˆ¶è§£æã€‘(250-300å­—)
                    - è¯¦ç»†è§£é‡ŠMulti-Head Attentionçš„å·¥ä½œåŸç†å’Œä»·å€¼
                    - è¯´æ˜ä½ç½®ç¼–ç (Positional Encoding)åœ¨åºåˆ—å»ºæ¨¡ä¸­çš„ä½œç”¨

                    ã€æ®µè½3 - å…³é”®ä¼˜åŒ–æ¼”è¿›ã€‘(200-250å­—)
                    - æŒ‰æ—¶é—´çº¿æ¢³ç†ä¸»è¦æ”¹è¿›æ–¹å‘
                    """,
                    estimated_word_count=650
                ),
                SubSection(
                    sub_section_title="ä¸»æµæ¨¡å‹æ€§èƒ½å¯¹æ¯”",
                    description="å¯¹æ¯”GPTç³»åˆ—ã€Claudeã€LLaMAç­‰ä¸»æµæ¨¡å‹",
                    writing_guidance="""
                    ã€æ®µè½1 - æ¨¡å‹æ¦‚è§ˆä¸åˆ†ç±»ã€‘(200-250å­—)
                    - åˆ—ä¸¾å½“å‰å¸‚åœºä¸»æµå¤§æ¨¡å‹

                    ã€æ®µè½2 - ç»¼åˆèƒ½åŠ›åŸºå‡†æµ‹è¯•ã€‘(350-400å­—)
                    - ä»‹ç»MMLUä½œä¸ºæœ€æƒå¨çš„ç»¼åˆè¯„æµ‹åŸºå‡†
                    """,
                    estimated_word_count=900
                ),
            ]
        ),

        Section(
            title="ç¬¬äºŒç«  AIå•†ä¸šåº”ç”¨å®è·µ",
            description="æ·±å…¥åˆ†æAIæŠ€æœ¯åœ¨å„è¡Œä¸šçš„è½åœ°åº”ç”¨æ¡ˆä¾‹",
            writing_guidance="ä»¥å®é™…æ¡ˆä¾‹ä¸ºä¸»å¯¼ï¼Œé‡‡ç”¨'è¡Œä¸šèƒŒæ™¯-ç—›ç‚¹åˆ†æ-è§£å†³æ–¹æ¡ˆ-æ•ˆæœè¯„ä¼°'çš„å››æ®µå¼ç»“æ„ã€‚",
            content_requirements="éœ€è¦åŒ…å«ï¼š1) 3ä¸ªä¸åŒè¡Œä¸šçš„æ·±åº¦æ¡ˆä¾‹ 2) æ¯ä¸ªæ¡ˆä¾‹çš„ROIæ•°æ®",
            visual_elements=True,
            estimated_words=1500,
            writing_priority="high",
            subsections=[
                SubSection(
                    sub_section_title="é‡‘èè¡Œä¸šï¼šæ™ºèƒ½é£æ§ä¸å®¢æœ",
                    description="åˆ†æAIåœ¨é“¶è¡Œã€ä¿é™©ç­‰é‡‘èæœºæ„çš„åº”ç”¨",
                    writing_guidance="""
                    ã€æ®µè½1 - è¡Œä¸šèƒŒæ™¯ä¸ç—›ç‚¹ã€‘(150-180å­—)
                    - æè¿°é‡‘èè¡Œä¸šé¢ä¸´çš„æ ¸å¿ƒæŒ‘æˆ˜

                    ã€æ®µè½2 - AIè§£å†³æ–¹æ¡ˆã€‘(280-320å­—)
                    - åˆ†ä¸¤ä¸ªåº”ç”¨åœºæ™¯å±•å¼€ï¼šé£æ§åº”ç”¨å’Œæ™ºèƒ½å®¢æœ
                    """,
                    estimated_word_count=650
                ),
            ]
        ),
    ]
)


# ========== æµ‹è¯•å‡½æ•° ==========

async def test_document_writing_graph():
    """
    æµ‹è¯•å®Œæ•´çš„ Document Writing Graph

    æµç¨‹ï¼š
    1. åˆ›å»ºåˆå§‹ state
    2. ç¼–è¯‘ Main Graph
    3. æ‰§è¡Œ graph
    4. éªŒè¯ç»“æœ
    """
    logger.info("\n" + "="*80)
    logger.info("å¼€å§‹æµ‹è¯• Document Writing Graph")
    logger.info("="*80 + "\n")

    # === 1. å‡†å¤‡æµ‹è¯•æ•°æ® ===
    logger.info("ğŸ“‹ [1/5] å‡†å¤‡æµ‹è¯•æ•°æ®...")

    # è®¡ç®—ç›®æ ‡æ€»å­—æ•°
    target_length = document_outline.estimated_total_words

    logger.info(f"  â†³ æ–‡æ¡£æ ‡é¢˜: {document_outline.title}")
    logger.info(f"  â†³ ç« èŠ‚æ•°é‡: {len(document_outline.sections)}")
    logger.info(f"  â†³ ç›®æ ‡æ€»å­—æ•°: {target_length}")
    logger.info(f"  â†³ å†™ä½œé£æ ¼: {document_outline.writing_style}")
    logger.info(f"  â†³ è¯­è¨€: {document_outline.language}\n")

    # === 2. åˆ›å»ºåˆå§‹çŠ¶æ€ ===
    logger.info("ğŸ”§ [2/5] åˆ›å»ºåˆå§‹çŠ¶æ€...")

    initial_state: DocumentState = {
        "chat_id": "test-chat-001",
        "document_id": "test-doc-001",
        "document_outline": document_outline,
    }

    logger.info("  âœ“ åˆå§‹çŠ¶æ€åˆ›å»ºå®Œæˆ\n")

    # === 3. ç¼–è¯‘ Main Graph ===
    logger.info("ğŸ—ï¸  [3/5] ç¼–è¯‘ Main Graph...")

    try:
        main_graph = create_main_graph()
        logger.info("  âœ“ Main Graph ç¼–è¯‘æˆåŠŸ\n")
    except Exception as e:
        logger.error(f"  âŒ Main Graph ç¼–è¯‘å¤±è´¥: {e}")
        raise

    # === 4. æ‰§è¡Œ Graph ===
    logger.info("ğŸš€ [4/5] æ‰§è¡Œ Document Writing Graph...")
    logger.info("  (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...)\n")

    import time
    start_time = time.time()

    try:
        # æ‰§è¡Œ graph
        result = await main_graph.ainvoke(initial_state)

        end_time = time.time()
        execution_time = end_time - start_time

        logger.info(f"\n  âœ“ Graph æ‰§è¡Œå®Œæˆ (è€—æ—¶: {execution_time:.2f}ç§’)\n")

    except Exception as e:
        logger.error(f"  âŒ Graph æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        raise

    # === 5. éªŒè¯ç»“æœ ===
    logger.info("âœ… [5/5] éªŒè¯ç»“æœ...")

    try:
        # æ£€æŸ¥ completed_chapters
        assert "completed_chapters" in result, "ç¼ºå°‘ completed_chapters"
        completed_chapters = result["completed_chapters"]
        expected_count = len(document_outline.sections)
        logger.info(f"  âœ“ å®Œæˆç« èŠ‚æ•°: {len(completed_chapters)}/{expected_count}")

        # æ£€æŸ¥æ‰€æœ‰ç« èŠ‚éƒ½å®Œæˆ
        expected_chapter_ids = set(range(1, expected_count + 1))
        actual_chapter_ids = set(completed_chapters.keys())
        assert expected_chapter_ids == actual_chapter_ids, f"ç« èŠ‚IDä¸åŒ¹é…: æœŸæœ› {expected_chapter_ids}, å®é™… {actual_chapter_ids}"

        # æ£€æŸ¥æ¯ä¸ªç« èŠ‚çš„ç»“æ„
        for ch_id, ch_data in completed_chapters.items():
            assert "content" in ch_data, f"ç« èŠ‚ {ch_id} ç¼ºå°‘ content"
            assert "metadata" in ch_data, f"ç« èŠ‚ {ch_id} ç¼ºå°‘ metadata"
            logger.info(f"  âœ“ ç« èŠ‚ {ch_id}: {len(ch_data['content'])} å­—ç¬¦, è¯„åˆ†: {ch_data['metadata'].get('final_score', 'N/A')}")

        # æ£€æŸ¥ document_metadata
        assert "document_metadata" in result, "ç¼ºå°‘ document_metadata"
        metadata = result["document_metadata"]
        logger.info(f"  âœ“ æ€»å­—æ•°: {metadata.get('total_words', 0)}")
        logger.info(f"  âœ“ å¹³å‡è¯„åˆ†: {metadata.get('avg_score', 0)}")

        # æ£€æŸ¥ document (æ•´åˆåæ–‡æ¡£)
        assert "document" in result, "ç¼ºå°‘ document"
        document = result["document"]
        assert len(document) > 0, "document ä¸ºç©º"
        logger.info(f"  âœ“ æœ€ç»ˆæ–‡æ¡£é•¿åº¦: {len(document)} å­—ç¬¦")

        # æ£€æŸ¥ document_review
        assert "document_review" in result, "ç¼ºå°‘ document_review"
        review = result["document_review"]
        logger.info(f"  âœ“ å®¡æŸ¥çŠ¶æ€: {review.get('status', 'N/A')}")
        logger.info(f"  âœ“ æ•´ä½“è¯„ä¼°: {review.get('overall_assessment', 'N/A')}")

        logger.info("\n" + "="*80)
        logger.success("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        logger.info("="*80 + "\n")

        # === 6. è¾“å‡ºæœ€ç»ˆæ–‡æ¡£é¢„è§ˆ ===
        logger.info("ğŸ“„ æœ€ç»ˆæ–‡æ¡£é¢„è§ˆ (å‰500å­—ç¬¦):\n")
        logger.info("-"*80)
        logger.info(document[:500] + "...\n")
        logger.info("-"*80 + "\n")

        return result

    except AssertionError as e:
        logger.error(f"  âŒ éªŒè¯å¤±è´¥: {e}")
        raise
    except Exception as e:
        logger.error(f"  âŒ éªŒè¯è¿‡ç¨‹å‡ºé”™: {e}", exc_info=True)
        raise


async def test_individual_nodes():
    """
    æµ‹è¯•å„ä¸ªç‹¬ç«‹èŠ‚ç‚¹

    ç”¨äºè°ƒè¯•å’ŒéªŒè¯å•ä¸ªèŠ‚ç‚¹çš„åŠŸèƒ½
    """
    logger.info("\n" + "="*80)
    logger.info("å¼€å§‹æµ‹è¯•ç‹¬ç«‹èŠ‚ç‚¹")
    logger.info("="*80 + "\n")

    from app.agents.core.publisher.writing.nodes import (
        chapter_dispatcher,
        chapter_aggregator,
        document_integrator,
        document_reviewer
    )

    # åˆ›å»ºåŸºç¡€ state
    base_state: DocumentState = {
        "chat_id": "test-chat-002",
        "document_id": "test-doc-002",
        "document_outline": document_outline,
        "writer_role": "æŠ€æœ¯åˆ†æå¸ˆ",
        "writer_profile": "ä¸“æ³¨äºAIå’Œç§‘æŠ€é¢†åŸŸçš„èµ„æ·±åˆ†æå¸ˆ",
        "writing_principles": ["å‡†ç¡®æ€§", "å®¢è§‚æ€§", "å‰ç»æ€§"],
        "completed_chapters": {},
        "document_metadata": {},
        "document_review": {},
        "document": "",
    }

    # === æµ‹è¯• 1: chapter_dispatcher ===
    logger.info("ğŸ§ª æµ‹è¯• chapter_dispatcher...")
    try:
        dispatcher_result = chapter_dispatcher(base_state)
        logger.info(f"  âœ“ dispatcher è¿”å›ç±»å‹: {type(dispatcher_result)}")
        logger.success("  âœ“ chapter_dispatcher æµ‹è¯•é€šè¿‡\n")
    except Exception as e:
        logger.error(f"  âŒ chapter_dispatcher æµ‹è¯•å¤±è´¥: {e}\n")

    # === æµ‹è¯• 2: chapter_aggregator ===
    logger.info("ğŸ§ª æµ‹è¯• chapter_aggregator...")
    try:
        # æ¨¡æ‹Ÿå·²å®Œæˆçš„ç« èŠ‚ (æ–°ç»“æ„ï¼Œå­—æ®µåä¸ merger_node ä¸€è‡´)
        aggregator_state = {
            **base_state,
            "completed_chapters": {
                1: {
                    "content": "# ç¬¬ä¸€ç« \n\nè¿™æ˜¯æµ‹è¯•å†…å®¹...",
                    "metadata": {
                        "chapter_id": 1,
                        "chapter_title": "ç¬¬ä¸€ç« ",
                        "word_count": 1200,
                        "revision_count": 1,
                        "final_score": 85,
                        "final_status": "pass",
                        "writer_role": "æŠ€æœ¯åˆ†æå¸ˆ",
                    }
                },
                2: {
                    "content": "# ç¬¬äºŒç« \n\nè¿™æ˜¯æµ‹è¯•å†…å®¹...",
                    "metadata": {
                        "chapter_id": 2,
                        "chapter_title": "ç¬¬äºŒç« ",
                        "word_count": 1300,
                        "revision_count": 0,
                        "final_score": 88,
                        "final_status": "pass",
                        "writer_role": "æŠ€æœ¯åˆ†æå¸ˆ",
                    }
                }
            }
        }

        aggregator_result = chapter_aggregator(aggregator_state)
        logger.info(f"  âœ“ aggregator è¿”å› document_metadata: {aggregator_result.get('document_metadata')}")
        logger.success("  âœ“ chapter_aggregator æµ‹è¯•é€šè¿‡\n")
    except Exception as e:
        logger.error(f"  âŒ chapter_aggregator æµ‹è¯•å¤±è´¥: {e}\n")
        aggregator_result = {}

    # === æµ‹è¯• 3: document_integrator ===
    logger.info("ğŸ§ª æµ‹è¯• document_integrator...")
    try:
        integrator_state = {
            **aggregator_state,
            "document_metadata": aggregator_result.get("document_metadata", {}),
        }

        integrator_result = await document_integrator(integrator_state)
        logger.info(f"  âœ“ integrator è¿”å›æ–‡æ¡£é•¿åº¦: {len(integrator_result.get('document', ''))}")
        logger.success("  âœ“ document_integrator æµ‹è¯•é€šè¿‡\n")
    except Exception as e:
        logger.error(f"  âŒ document_integrator æµ‹è¯•å¤±è´¥: {e}\n")
        integrator_result = {}

    # === æµ‹è¯• 4: document_reviewer ===
    logger.info("ğŸ§ª æµ‹è¯• document_reviewer...")
    try:
        reviewer_state = {
            **integrator_state,
            "document": integrator_result.get("document", "# æµ‹è¯•æ–‡æ¡£\n\nè¿™æ˜¯æµ‹è¯•å†…å®¹..."),
        }

        reviewer_result = await document_reviewer(reviewer_state)
        latest_review = reviewer_result.get('latest_review')
        if latest_review:
            logger.info(f"  âœ“ reviewer è¿”å›å®¡æŸ¥çŠ¶æ€: {latest_review.status}")
            logger.info(f"  âœ“ reviewer è¿”å›è¯„åˆ†: {latest_review.score}")
            logger.info(f"  âœ“ reviewer è¿”å›å»ºè®®æ•°: {len(latest_review.actionable_suggestions)}")
        logger.info(f"  âœ“ reviewer ä¿®è®¢æ¬¡æ•°: {reviewer_result.get('revision_count')}")
        logger.success("  âœ“ document_reviewer æµ‹è¯•é€šè¿‡\n")
    except Exception as e:
        logger.error(f"  âŒ document_reviewer æµ‹è¯•å¤±è´¥: {e}\n")

    logger.info("="*80)
    logger.success("âœ… ç‹¬ç«‹èŠ‚ç‚¹æµ‹è¯•å®Œæˆï¼")
    logger.info("="*80 + "\n")


# ========== ä¸»å‡½æ•° ==========

async def main():
    """ä¸»æµ‹è¯•å…¥å£"""
    logger.info("\n" + "ğŸ¯ " + "="*74)
    logger.info("ğŸ¯  Document Writing Graph æµ‹è¯•å¥—ä»¶")
    logger.info("ğŸ¯ " + "="*74 + "\n")

    # é€‰æ‹©æµ‹è¯•æ¨¡å¼
    test_mode = "full"  # å¯é€‰: "full", "nodes", "both"

    if test_mode in ["full", "both"]:
        logger.info("ğŸ“Œ è¿è¡Œå®Œæ•´ Graph æµ‹è¯•...\n")
        await test_document_writing_graph()

    if test_mode in ["nodes", "both"]:
        logger.info("ğŸ“Œ è¿è¡Œç‹¬ç«‹èŠ‚ç‚¹æµ‹è¯•...\n")
        await test_individual_nodes()

    logger.info("\n" + "ğŸ‰ " + "="*74)
    logger.success("ğŸ‰  æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    logger.info("ğŸ‰ " + "="*74 + "\n")


if __name__ == "__main__":
    asyncio.run(main())
